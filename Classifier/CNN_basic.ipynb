{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Grappling with a CNN\n",
    "\n",
    "This notebook will convince me that I can build a CNN."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Libraries\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import random\n",
    "import tensorflow as tf\n",
    "import tensorflow.keras as keras\n",
    "import tensorboard\n",
    "import psycopg2\n",
    "from PIL import Image\n",
    "import os\n",
    "import h5py\n",
    "import datetime\n",
    "%load_ext tensorboard\n",
    "!rm -rf ./logs/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The data are stored locally in a PostgreSQL database. So let's connect and get them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Attempting to connect to PostgreSQL.\n",
      "Selecting rows from origami_images table.\n",
      "PostgreSQL connection closed.\n"
     ]
    }
   ],
   "source": [
    "# Read in data from origami database in PostgreSQL\n",
    "try:\n",
    "    print('Attempting to connect to PostgreSQL.')\n",
    "    conn = None\n",
    "    conn = psycopg2.connect(host='localhost', database='origami', user='postgres', password='postgres')\n",
    "    cur = conn.cursor()\n",
    "    # SELECT image classifications and file paths from PostgreSQL\n",
    "    sql_select = \"SELECT image_class, image_path FROM origami_images;\"\n",
    "    cur.execute(sql_select)\n",
    "    print('Selecting rows from origami_images table.')\n",
    "    origami_images = cur.fetchall()\n",
    "except (Exception, psycopg2.DatabaseError) as error:\n",
    "    print(error)\n",
    "finally:\n",
    "    if conn is not None:\n",
    "        cur.close()\n",
    "        conn.close()\n",
    "        print('PostgreSQL connection closed.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This gives us `origami_images`, a list of tuples, each of which gives a class and a file path for the associated image."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1150\n",
      "('butterfly', '/Users/wwatson/Desktop/Insight/Project/origami/Images/downloads/butterfly/63.jpg')\n"
     ]
    }
   ],
   "source": [
    "print(len(origami_images))\n",
    "print(origami_images[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's shuffle this list randomly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "random.shuffle(origami_images)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We'll turn this into two `numpy` arrays to train our model. The class names are easy enough."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['frog' 'duck' 'crane' 'lotus' 'butterfly' 'star']\n",
      "(1150,)\n"
     ]
    }
   ],
   "source": [
    "image_classes = []\n",
    "class_names = []\n",
    "for img in origami_images:\n",
    "    image_classes.append(img[0])\n",
    "    if img[0] not in class_names:\n",
    "        class_names.append(img[0])\n",
    "image_classes = np.array(image_classes)\n",
    "class_names = np.array(class_names)\n",
    "print(class_names)\n",
    "print(image_classes.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1150, 6)\n"
     ]
    }
   ],
   "source": [
    "def get_label(label):\n",
    "    return label == class_names\n",
    "\n",
    "origami_y = []\n",
    "for label in image_classes:\n",
    "    origami_y.append(get_label(label))\n",
    "origami_y = tf.convert_to_tensor(origami_y)\n",
    "print(origami_y.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The images are a little harder. Let's define a couple of functions to help with image processing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Side length of normalized image\n",
    "IMG_SIZE = 256\n",
    "\n",
    "# Function to decode an image, render in grayscale and square dimensions\n",
    "def decode_img(img):\n",
    "    img = tf.io.decode_image(img, expand_animations=False)\n",
    "    img = tf.image.convert_image_dtype(img, tf.float64)\n",
    "    img = tf.image.rgb_to_grayscale(img)\n",
    "    return tf.image.resize(img, [IMG_SIZE, IMG_SIZE])\n",
    "\n",
    "# Function to process a file path and return the image\n",
    "def process_path(img_path):\n",
    "    # Decode image using auxiliary function\n",
    "    img = tf.io.read_file(img_path)\n",
    "    img = decode_img(img)\n",
    "    return img"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "OK, so now let's create our second array."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/wwatson/Desktop/Insight/Project/origami/Images/downloads/frog/41.jpg\n",
      "/Users/wwatson/Desktop/Insight/Project/origami/Images/downloads/duck/118.jpg\n",
      "/Users/wwatson/Desktop/Insight/Project/origami/Images/downloads/crane/106.jpg\n",
      "/Users/wwatson/Desktop/Insight/Project/origami/Images/downloads/lotus/98.jpg\n",
      "/Users/wwatson/Desktop/Insight/Project/origami/Images/downloads/lotus/88.jpg\n",
      "/Users/wwatson/Desktop/Insight/Project/origami/Images/downloads/frog/91.jpg\n",
      "/Users/wwatson/Desktop/Insight/Project/origami/Images/downloads/lotus/31.jpg\n",
      "/Users/wwatson/Desktop/Insight/Project/origami/Images/downloads/crane/149.jpg\n",
      "/Users/wwatson/Desktop/Insight/Project/origami/Images/downloads/frog/17.jpg\n",
      "/Users/wwatson/Desktop/Insight/Project/origami/Images/downloads/crane/115.jpg\n",
      "/Users/wwatson/Desktop/Insight/Project/origami/Images/downloads/duck/109.jpg\n",
      "/Users/wwatson/Desktop/Insight/Project/origami/Images/downloads/lotus/78.jpg\n",
      "/Users/wwatson/Desktop/Insight/Project/origami/Images/downloads/lotus/28.jpg\n",
      "/Users/wwatson/Desktop/Insight/Project/origami/Images/downloads/duck/121.jpg\n",
      "/Users/wwatson/Desktop/Insight/Project/origami/Images/downloads/crane/59.jpg\n",
      "/Users/wwatson/Desktop/Insight/Project/origami/Images/downloads/frog/23.jpg\n",
      "/Users/wwatson/Desktop/Insight/Project/origami/Images/downloads/frog/61.jpg\n",
      "/Users/wwatson/Desktop/Insight/Project/origami/Images/downloads/duck/27.jpg\n",
      "/Users/wwatson/Desktop/Insight/Project/origami/Images/downloads/lotus/92.jpg\n",
      "/Users/wwatson/Desktop/Insight/Project/origami/Images/downloads/crane/188.jpg\n",
      "/Users/wwatson/Desktop/Insight/Project/origami/Images/downloads/duck/112.jpg\n",
      "/Users/wwatson/Desktop/Insight/Project/origami/Images/downloads/lotus/175.jpg\n",
      "/Users/wwatson/Desktop/Insight/Project/origami/Images/downloads/duck/13.jpg\n",
      "/Users/wwatson/Desktop/Insight/Project/origami/Images/downloads/frog/136.jpg\n",
      "/Users/wwatson/Desktop/Insight/Project/origami/Images/downloads/frog/159.jpg\n",
      "25 files processed.\n",
      "/Users/wwatson/Desktop/Insight/Project/origami/Images/downloads/crane/51.jpg\n",
      "/Users/wwatson/Desktop/Insight/Project/origami/Images/downloads/frog/172.jpg\n",
      "/Users/wwatson/Desktop/Insight/Project/origami/Images/downloads/butterfly/155.jpg\n",
      "/Users/wwatson/Desktop/Insight/Project/origami/Images/downloads/duck/49.jpg\n",
      "/Users/wwatson/Desktop/Insight/Project/origami/Images/downloads/butterfly/30.jpg\n",
      "/Users/wwatson/Desktop/Insight/Project/origami/Images/downloads/duck/78.jpg\n",
      "/Users/wwatson/Desktop/Insight/Project/origami/Images/downloads/frog/94.jpg\n",
      "/Users/wwatson/Desktop/Insight/Project/origami/Images/downloads/butterfly/122.jpg\n",
      "/Users/wwatson/Desktop/Insight/Project/origami/Images/downloads/butterfly/114.png\n",
      "/Users/wwatson/Desktop/Insight/Project/origami/Images/downloads/star/151.jpg\n",
      "/Users/wwatson/Desktop/Insight/Project/origami/Images/downloads/crane/165.jpg\n",
      "/Users/wwatson/Desktop/Insight/Project/origami/Images/downloads/duck/141.jpg\n",
      "/Users/wwatson/Desktop/Insight/Project/origami/Images/downloads/lotus/89.jpg\n",
      "/Users/wwatson/Desktop/Insight/Project/origami/Images/downloads/duck/56.jpg\n",
      "/Users/wwatson/Desktop/Insight/Project/origami/Images/downloads/frog/22.jpg\n",
      "/Users/wwatson/Desktop/Insight/Project/origami/Images/downloads/frog/125.jpg\n",
      "/Users/wwatson/Desktop/Insight/Project/origami/Images/downloads/lotus/38.jpg\n",
      "/Users/wwatson/Desktop/Insight/Project/origami/Images/downloads/frog/87.jpg\n",
      "/Users/wwatson/Desktop/Insight/Project/origami/Images/downloads/butterfly/9.jpg\n",
      "/Users/wwatson/Desktop/Insight/Project/origami/Images/downloads/crane/187.jpg\n",
      "/Users/wwatson/Desktop/Insight/Project/origami/Images/downloads/lotus/123.jpg\n",
      "/Users/wwatson/Desktop/Insight/Project/origami/Images/downloads/lotus/125.jpg\n",
      "/Users/wwatson/Desktop/Insight/Project/origami/Images/downloads/crane/71.jpg\n",
      "/Users/wwatson/Desktop/Insight/Project/origami/Images/downloads/butterfly/10.jpg\n",
      "/Users/wwatson/Desktop/Insight/Project/origami/Images/downloads/star/123.jpg\n",
      "50 files processed.\n",
      "/Users/wwatson/Desktop/Insight/Project/origami/Images/downloads/star/10.jpg\n",
      "/Users/wwatson/Desktop/Insight/Project/origami/Images/downloads/lotus/156.jpg\n",
      "/Users/wwatson/Desktop/Insight/Project/origami/Images/downloads/butterfly/118.jpg\n",
      "/Users/wwatson/Desktop/Insight/Project/origami/Images/downloads/lotus/103.jpg\n",
      "/Users/wwatson/Desktop/Insight/Project/origami/Images/downloads/star/108.jpg\n",
      "/Users/wwatson/Desktop/Insight/Project/origami/Images/downloads/star/9.jpg\n",
      "/Users/wwatson/Desktop/Insight/Project/origami/Images/downloads/frog/102.jpg\n",
      "/Users/wwatson/Desktop/Insight/Project/origami/Images/downloads/frog/144.jpg\n",
      "/Users/wwatson/Desktop/Insight/Project/origami/Images/downloads/crane/95.jpg\n",
      "/Users/wwatson/Desktop/Insight/Project/origami/Images/downloads/star/120.jpg\n",
      "/Users/wwatson/Desktop/Insight/Project/origami/Images/downloads/lotus/113.jpg\n",
      "/Users/wwatson/Desktop/Insight/Project/origami/Images/downloads/lotus/104.jpg\n",
      "/Users/wwatson/Desktop/Insight/Project/origami/Images/downloads/butterfly/48.jpg\n",
      "/Users/wwatson/Desktop/Insight/Project/origami/Images/downloads/butterfly/105.jpg\n",
      "/Users/wwatson/Desktop/Insight/Project/origami/Images/downloads/butterfly/150.jpg\n",
      "/Users/wwatson/Desktop/Insight/Project/origami/Images/downloads/frog/54.jpg\n",
      "/Users/wwatson/Desktop/Insight/Project/origami/Images/downloads/lotus/83.jpg\n",
      "/Users/wwatson/Desktop/Insight/Project/origami/Images/downloads/butterfly/29.jpg\n",
      "/Users/wwatson/Desktop/Insight/Project/origami/Images/downloads/butterfly/133.jpg\n",
      "/Users/wwatson/Desktop/Insight/Project/origami/Images/downloads/star/48.jpg\n",
      "/Users/wwatson/Desktop/Insight/Project/origami/Images/downloads/star/152.jpg\n",
      "/Users/wwatson/Desktop/Insight/Project/origami/Images/downloads/star/45.jpg\n",
      "/Users/wwatson/Desktop/Insight/Project/origami/Images/downloads/star/193.jpg\n",
      "/Users/wwatson/Desktop/Insight/Project/origami/Images/downloads/duck/133.jpg\n",
      "/Users/wwatson/Desktop/Insight/Project/origami/Images/downloads/crane/146.jpg\n",
      "75 files processed.\n",
      "/Users/wwatson/Desktop/Insight/Project/origami/Images/downloads/crane/84.jpg\n",
      "/Users/wwatson/Desktop/Insight/Project/origami/Images/downloads/duck/184.jpg\n",
      "/Users/wwatson/Desktop/Insight/Project/origami/Images/downloads/crane/10.jpg\n",
      "/Users/wwatson/Desktop/Insight/Project/origami/Images/downloads/lotus/55.jpg\n",
      "/Users/wwatson/Desktop/Insight/Project/origami/Images/downloads/butterfly/77.jpg\n",
      "/Users/wwatson/Desktop/Insight/Project/origami/Images/downloads/lotus/35.jpg\n",
      "/Users/wwatson/Desktop/Insight/Project/origami/Images/downloads/butterfly/42.jpg\n",
      "/Users/wwatson/Desktop/Insight/Project/origami/Images/downloads/crane/116.jpg\n",
      "/Users/wwatson/Desktop/Insight/Project/origami/Images/downloads/crane/24.jpg\n",
      "/Users/wwatson/Desktop/Insight/Project/origami/Images/downloads/star/79.jpg\n",
      "/Users/wwatson/Desktop/Insight/Project/origami/Images/downloads/frog/6.jpg\n",
      "/Users/wwatson/Desktop/Insight/Project/origami/Images/downloads/lotus/101.jpg\n",
      "/Users/wwatson/Desktop/Insight/Project/origami/Images/downloads/lotus/60.jpg\n",
      "/Users/wwatson/Desktop/Insight/Project/origami/Images/downloads/star/13.jpg\n",
      "/Users/wwatson/Desktop/Insight/Project/origami/Images/downloads/duck/64.jpg\n",
      "/Users/wwatson/Desktop/Insight/Project/origami/Images/downloads/lotus/70.jpg\n",
      "/Users/wwatson/Desktop/Insight/Project/origami/Images/downloads/crane/67.jpg\n",
      "/Users/wwatson/Desktop/Insight/Project/origami/Images/downloads/star/20.jpg\n",
      "/Users/wwatson/Desktop/Insight/Project/origami/Images/downloads/frog/44.jpg\n",
      "/Users/wwatson/Desktop/Insight/Project/origami/Images/downloads/duck/122.jpg\n",
      "/Users/wwatson/Desktop/Insight/Project/origami/Images/downloads/frog/11.jpg\n",
      "/Users/wwatson/Desktop/Insight/Project/origami/Images/downloads/frog/155.jpg\n",
      "/Users/wwatson/Desktop/Insight/Project/origami/Images/downloads/duck/132.jpg\n",
      "/Users/wwatson/Desktop/Insight/Project/origami/Images/downloads/frog/85.jpg\n",
      "/Users/wwatson/Desktop/Insight/Project/origami/Images/downloads/crane/169.jpg\n",
      "100 files processed.\n",
      "/Users/wwatson/Desktop/Insight/Project/origami/Images/downloads/butterfly/128.jpg\n",
      "/Users/wwatson/Desktop/Insight/Project/origami/Images/downloads/duck/31.jpg\n",
      "/Users/wwatson/Desktop/Insight/Project/origami/Images/downloads/duck/28.jpg\n",
      "/Users/wwatson/Desktop/Insight/Project/origami/Images/downloads/crane/179.jpg\n",
      "/Users/wwatson/Desktop/Insight/Project/origami/Images/downloads/star/16.jpg\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/wwatson/Desktop/Insight/Project/origami/Images/downloads/frog/147.jpg\n",
      "/Users/wwatson/Desktop/Insight/Project/origami/Images/downloads/crane/72.jpg\n",
      "/Users/wwatson/Desktop/Insight/Project/origami/Images/downloads/lotus/5.jpg\n",
      "/Users/wwatson/Desktop/Insight/Project/origami/Images/downloads/crane/7.jpg\n",
      "/Users/wwatson/Desktop/Insight/Project/origami/Images/downloads/star/91.jpg\n",
      "/Users/wwatson/Desktop/Insight/Project/origami/Images/downloads/crane/64.jpg\n",
      "/Users/wwatson/Desktop/Insight/Project/origami/Images/downloads/crane/120.jpg\n",
      "/Users/wwatson/Desktop/Insight/Project/origami/Images/downloads/frog/152.jpg\n",
      "/Users/wwatson/Desktop/Insight/Project/origami/Images/downloads/star/181.jpg\n",
      "/Users/wwatson/Desktop/Insight/Project/origami/Images/downloads/crane/117.png\n"
     ]
    },
    {
     "ename": "InvalidArgumentError",
     "evalue": "Matrix size-incompatible: In[0]: [367500,4], In[1]: [3,1] [Op:MatMul] name: rgb_to_grayscale/Tensordot/MatMul/",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mInvalidArgumentError\u001b[0m                      Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-19-2cd888165fd4>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mimg\u001b[0m \u001b[0;32min\u001b[0m \u001b[0morigami_images\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m     \u001b[0morigami_X\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprocess_path\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m     \u001b[0mcounter\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mcounter\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0;36m25\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-18-8422c920d2c3>\u001b[0m in \u001b[0;36mprocess_path\u001b[0;34m(img_path)\u001b[0m\n\u001b[1;32m     13\u001b[0m     \u001b[0;31m# Decode image using auxiliary function\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m     \u001b[0mimg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mio\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_file\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 15\u001b[0;31m     \u001b[0mimg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdecode_img\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     16\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mimg\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-18-8422c920d2c3>\u001b[0m in \u001b[0;36mdecode_img\u001b[0;34m(img)\u001b[0m\n\u001b[1;32m      6\u001b[0m     \u001b[0mimg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mio\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdecode_image\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexpand_animations\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m     \u001b[0mimg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimage\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconvert_image_dtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloat64\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m     \u001b[0mimg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimage\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrgb_to_grayscale\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      9\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimage\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mIMG_SIZE\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mIMG_SIZE\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/envs/origami/lib/python3.7/site-packages/tensorflow_core/python/ops/image_ops_impl.py\u001b[0m in \u001b[0;36mrgb_to_grayscale\u001b[0;34m(images, name)\u001b[0m\n\u001b[1;32m   1844\u001b[0m     \u001b[0;31m# https://en.wikipedia.org/wiki/Luma_%28video%29\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1845\u001b[0m     \u001b[0mrgb_weights\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;36m0.2989\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0.5870\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0.1140\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1846\u001b[0;31m     \u001b[0mgray_float\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmath_ops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtensordot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mflt_image\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrgb_weights\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1847\u001b[0m     \u001b[0mgray_float\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0marray_ops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexpand_dims\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgray_float\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1848\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mconvert_image_dtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgray_float\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0morig_dtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/envs/origami/lib/python3.7/site-packages/tensorflow_core/python/ops/math_ops.py\u001b[0m in \u001b[0;36mtensordot\u001b[0;34m(a, b, axes, name)\u001b[0m\n\u001b[1;32m   4075\u001b[0m     b_reshape, b_free_dims, b_free_dims_static = _tensordot_reshape(\n\u001b[1;32m   4076\u001b[0m         b, b_axes, True)\n\u001b[0;32m-> 4077\u001b[0;31m     \u001b[0mab_matmul\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmatmul\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ma_reshape\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mb_reshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   4078\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ma_free_dims\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mb_free_dims\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4079\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0marray_ops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mab_matmul\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0ma_free_dims\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mb_free_dims\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/envs/origami/lib/python3.7/site-packages/tensorflow_core/python/util/dispatch.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    178\u001b[0m     \u001b[0;34m\"\"\"Call target, and fall back on dispatchers if there is a TypeError.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    179\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 180\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    181\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mTypeError\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    182\u001b[0m       \u001b[0;31m# Note: convert_to_eager_tensor currently raises a ValueError, not a\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/envs/origami/lib/python3.7/site-packages/tensorflow_core/python/ops/math_ops.py\u001b[0m in \u001b[0;36mmatmul\u001b[0;34m(a, b, transpose_a, transpose_b, adjoint_a, adjoint_b, a_is_sparse, b_is_sparse, name)\u001b[0m\n\u001b[1;32m   2763\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2764\u001b[0m       return gen_math_ops.mat_mul(\n\u001b[0;32m-> 2765\u001b[0;31m           a, b, transpose_a=transpose_a, transpose_b=transpose_b, name=name)\n\u001b[0m\u001b[1;32m   2766\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2767\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/envs/origami/lib/python3.7/site-packages/tensorflow_core/python/ops/gen_math_ops.py\u001b[0m in \u001b[0;36mmat_mul\u001b[0;34m(a, b, transpose_a, transpose_b, name)\u001b[0m\n\u001b[1;32m   6124\u001b[0m       \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   6125\u001b[0m         \u001b[0mmessage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmessage\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 6126\u001b[0;31m       \u001b[0m_six\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mraise_from\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_core\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_status_to_exception\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   6127\u001b[0m   \u001b[0;31m# Add nodes to the TensorFlow graph.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   6128\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0mtranspose_a\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/envs/origami/lib/python3.7/site-packages/six.py\u001b[0m in \u001b[0;36mraise_from\u001b[0;34m(value, from_value)\u001b[0m\n",
      "\u001b[0;31mInvalidArgumentError\u001b[0m: Matrix size-incompatible: In[0]: [367500,4], In[1]: [3,1] [Op:MatMul] name: rgb_to_grayscale/Tensordot/MatMul/"
     ]
    }
   ],
   "source": [
    "origami_X = []\n",
    "counter = 0\n",
    "for img in origami_images:\n",
    "    print(img[1])\n",
    "    origami_X.append(process_path(img[1]))\n",
    "    counter += 1\n",
    "    if counter % 25 == 0:\n",
    "        print('{} files processed.'.format(counter))\n",
    "print('All files processed. Converting to tensor.')\n",
    "origami_X = tf.convert_to_tensor(origami_X)\n",
    "print(origami_X.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "OK, let's give this CNN thing a whirl..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "cnn = keras.Sequential()\n",
    "# Layer construction w/ L2 regularizers on convolutional layers\n",
    "cnn.add(keras.layers.Conv2D(32, (3, 3), activation='relu', input_shape=(IMG_SIZE, IMG_SIZE, 1)))\n",
    "cnn.add(keras.layers.MaxPooling2D((2, 2)))\n",
    "cnn.add(keras.layers.Conv2D(64, (3, 3), activation='relu'))\n",
    "cnn.add(keras.layers.Flatten())\n",
    "cnn.add(keras.layers.Dense(16, activation='relu'))\n",
    "cnn.add(keras.layers.Dense(len(class_names), activation='softmax'))\n",
    "cnn.add(keras.layers.Reshape((-1,)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Compile it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_2 (Conv2D)            (None, 254, 254, 32)      320       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2 (None, 127, 127, 32)      0         \n",
      "_________________________________________________________________\n",
      "conv2d_3 (Conv2D)            (None, 125, 125, 64)      18496     \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 1000000)           0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 16)                16000016  \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 5)                 85        \n",
      "_________________________________________________________________\n",
      "reshape_1 (Reshape)          (None, None)              0         \n",
      "=================================================================\n",
      "Total params: 16,018,917\n",
      "Trainable params: 16,018,917\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "cnn.compile(optimizer='adam',\n",
    "           loss=keras.losses.CategoricalCrossentropy(from_logits=True),\n",
    "           metrics=[keras.losses.CategoricalCrossentropy(from_logits=True),\n",
    "                    'categorical_accuracy'])\n",
    "cnn.summary()\n",
    "\n",
    "log_dir = \"logs/fit/\" + datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\")\n",
    "tensorboard_callback = tf.keras.callbacks.TensorBoard(log_dir=log_dir, histogram_freq=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And fit it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 166 samples\n",
      "Epoch 1/16\n",
      "166/166 [==============================] - 37s 222ms/sample - loss: 1.7031 - categorical_crossentropy: 1.6853 - categorical_accuracy: 0.1807\n",
      "Epoch 2/16\n",
      "166/166 [==============================] - 20s 121ms/sample - loss: 1.7060 - categorical_crossentropy: 1.6878 - categorical_accuracy: 0.1988\n",
      "Epoch 3/16\n",
      "166/166 [==============================] - 19s 117ms/sample - loss: 1.7060 - categorical_crossentropy: 1.7330 - categorical_accuracy: 0.1988\n",
      "Epoch 4/16\n",
      "166/166 [==============================] - 18s 109ms/sample - loss: 1.7060 - categorical_crossentropy: 1.6878 - categorical_accuracy: 0.1988\n",
      "Epoch 5/16\n",
      "166/166 [==============================] - 19s 117ms/sample - loss: 1.7060 - categorical_crossentropy: 1.6652 - categorical_accuracy: 0.1988\n",
      "Epoch 6/16\n",
      "166/166 [==============================] - 18s 110ms/sample - loss: 1.7060 - categorical_crossentropy: 1.7104 - categorical_accuracy: 0.1988\n",
      "Epoch 7/16\n",
      "166/166 [==============================] - 17s 104ms/sample - loss: 1.7060 - categorical_crossentropy: 1.6878 - categorical_accuracy: 0.1988\n",
      "Epoch 8/16\n",
      "166/166 [==============================] - 22s 134ms/sample - loss: 1.7060 - categorical_crossentropy: 1.7330 - categorical_accuracy: 0.1988\n",
      "Epoch 9/16\n",
      "166/166 [==============================] - 22s 131ms/sample - loss: 1.7060 - categorical_crossentropy: 1.6878 - categorical_accuracy: 0.1988\n",
      "Epoch 10/16\n",
      "166/166 [==============================] - 18s 111ms/sample - loss: 1.7060 - categorical_crossentropy: 1.7104 - categorical_accuracy: 0.1988\n",
      "Epoch 11/16\n",
      "166/166 [==============================] - 18s 109ms/sample - loss: 1.7060 - categorical_crossentropy: 1.6878 - categorical_accuracy: 0.1988\n",
      "Epoch 12/16\n",
      "166/166 [==============================] - 17s 104ms/sample - loss: 1.7060 - categorical_crossentropy: 1.7104 - categorical_accuracy: 0.1988\n",
      "Epoch 13/16\n",
      "166/166 [==============================] - 18s 107ms/sample - loss: 1.7060 - categorical_crossentropy: 1.7330 - categorical_accuracy: 0.1988\n",
      "Epoch 14/16\n",
      "166/166 [==============================] - 17s 101ms/sample - loss: 1.7060 - categorical_crossentropy: 1.7330 - categorical_accuracy: 0.1988\n",
      "Epoch 15/16\n",
      "166/166 [==============================] - 21s 128ms/sample - loss: 1.7060 - categorical_crossentropy: 1.7330 - categorical_accuracy: 0.1988\n",
      "Epoch 16/16\n",
      "166/166 [==============================] - 19s 113ms/sample - loss: 1.7060 - categorical_crossentropy: 1.6878 - categorical_accuracy: 0.1988\n"
     ]
    }
   ],
   "source": [
    "history = cnn.fit(origami_X, origami_y, epochs=16, callbacks=[tensorboard_callback])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "      <iframe id=\"tensorboard-frame-2966f791da89977f\" width=\"100%\" height=\"800\" frameborder=\"0\">\n",
       "      </iframe>\n",
       "      <script>\n",
       "        (function() {\n",
       "          const frame = document.getElementById(\"tensorboard-frame-2966f791da89977f\");\n",
       "          const url = new URL(\"/\", window.location);\n",
       "          url.port = 6006;\n",
       "          frame.src = url;\n",
       "        })();\n",
       "      </script>\n",
       "  "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%tensorboard --logdir logs/fit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "firstEnv",
   "language": "python",
   "name": "firstenv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
